{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import os\n",
    "from random import randint, randrange\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, make_scorer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "import mlxtend\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity='all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(os.getcwd(),'dataset')\n",
    "# output_folder = '/content/drive/MyDrive/ML Challenge Datasets/Output Folder'\n",
    "result_path = os.path.join(os.getcwd(),'Submissions')\n",
    "files = os.listdir(dataset_path)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(dataset_path,files[1]),low_memory=False)\n",
    "test_data = pd.read_csv(os.path.join(dataset_path,files[0]),low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "'''\n",
    "Combine All Issue columns into one single column with Issue as a binary variable and number of issues as another column\n",
    "'''\n",
    "issue_cols = [col for col in train if col.startswith('issue')]\n",
    "train['Issue_Count'] = train[issue_cols].apply(lambda x: x.count(), axis=1)\n",
    "train['Issue_Y_N'] = np.where(train['Issue_Count']== 0, 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the same on Test Data\n",
    "test_data['Issue_Count'] = test_data[issue_cols].apply(lambda x: x.count(), axis=1)\n",
    "test_data['Issue_Y_N'] = np.where(test_data['Issue_Count']== 0, 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Value Treatment\n",
    "limit_per = len(train)*0.70\n",
    "train_clean = train.dropna(thresh=limit_per,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = train_clean.dropna()\n",
    "len(train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Columns with Zero Variance\n",
    "train_clean_col = train_clean\n",
    "for col in train_clean.columns:\n",
    "    #print('Cols {}'.format(col))\n",
    "    if len(train_clean[col].unique())==1:\n",
    "        #print('Removing feature: {}'.format(col))\n",
    "        train_clean_col = train_clean_col.drop(col,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Other Redundant Features\n",
    "feat_remove = ['appno','country.alpha2','docname','ecli','itemid','originatingbody','sharepointid','parties.1','judgementdate',\\\n",
    "               'kpdate','respondentOrderEng','parties.0']\n",
    "train_cleaned = train_clean_col.drop(feat_remove,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to remove from Test set\n",
    "cols_to_remove = list(set(train.columns.tolist())-set(train_cleaned.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace (-,=,.) with (_) in column names\n",
    "train_cleaned.columns=train_cleaned.columns.str.replace('=','_')\n",
    "train_cleaned.columns=train_cleaned.columns.str.replace('-','_')\n",
    "train_cleaned.columns=train_cleaned.columns.str.replace('.','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find CCL columns replace (-1) with (2) and one-hot encode all columns that need to be encoded\n",
    "ccl_cols = [col for col in train_cleaned if col.startswith('ccl')]\n",
    "train_cleaned[ccl_cols] = train_cleaned[ccl_cols].replace([-1],[2])\n",
    "feature_encode_cols = ccl_cols + train_cleaned.select_dtypes(include=['object']).columns.tolist()+['typedescription']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE\n",
    "ohe = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
    "array_hot_encoded = ohe.fit_transform(train_cleaned[feature_encode_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# All columns after encoding\n",
    "column_names = []\n",
    "C=0\n",
    "for i in ohe.categories_:\n",
    "  print(list(feature_encode_cols[C]+'_'+pd.Series(i).apply(str)))\n",
    "  column_names.extend(list(feature_encode_cols[C]+'_'+pd.Series(i).apply(str)))\n",
    "  C=C+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hot_encoded = pd.DataFrame(array_hot_encoded, index=train_cleaned.index,columns=column_names,dtype=np.int64)\n",
    "data_others = train_cleaned.drop(feature_encode_cols,axis=1)\n",
    "train_final = pd.concat([data_hot_encoded,data_others],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply same on test\n",
    "test_data_1 = test_data.drop(cols_to_remove,axis=1)\n",
    "test_data_1.columns=test_data_1.columns.str.replace('=','_')\n",
    "test_data_1.columns=test_data_1.columns.str.replace('-','_')\n",
    "test_data_1.columns=test_data_1.columns.str.replace('.','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_1[ccl_cols] = test_data_1[ccl_cols].replace([-1],[2])\n",
    "array_hot_encoded_test = ohe.transform(test_data_1[feature_encode_cols])\n",
    "data_hot_encoded_test = pd.DataFrame(array_hot_encoded_test, index=test_data_1.index,columns=column_names,dtype=np.int64)\n",
    "data_others_test = test_data_1.drop(feature_encode_cols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final = pd.concat([data_hot_encoded_test,data_others_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_final.columns.tolist()))\n",
    "print(len(test_final.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Train and Test\n",
    "\n",
    "## Define X, y\n",
    "X = train_final.drop(['importance'],axis=1).values\n",
    "y = train_final['importance'].values\n",
    "\n",
    "# Split Train Test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42,stratify=y)\n",
    "\n",
    "# Test Submission Matrix\n",
    "\n",
    "test_matrix = test_final.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Weight for Train Split and Full Training Set\n",
    "\n",
    "## Class Weight for Training Split\n",
    "from sklearn.utils import class_weight\n",
    "class_weights_train = list(class_weight.compute_class_weight('balanced',\n",
    "                                             np.unique(train_final['importance']),\n",
    "                                             y_train,classes=[1,2,3,4]))\n",
    "\n",
    "w_array = np.ones(y_train.shape[0], dtype = 'float')\n",
    "for i, val in enumerate(y_train):\n",
    "    w_array[i] = class_weights_train[val-1]\n",
    "\n",
    "    \n",
    "## Class Weight for Full Training Set\n",
    "class_weights_ft = list(class_weight.compute_class_weight('balanced',\n",
    "                                             np.unique(train_final['importance']),\n",
    "                                             train_final['importance'],classes=[1,2,3,4]))\n",
    "\n",
    "w_array_ft = np.ones(y.shape[0], dtype = 'float')\n",
    "for i, val in enumerate(y):\n",
    "    w_array_ft[i] = class_weights_ft[val-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid XGBoost\n",
    "model = xgb.XGBClassifier(random_state=123,objective='multi:softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate':[0.1,0.01,0.5,0.05],\n",
    "    'colsample_bytree':[0.2,0.4,0.6,0.8,1],\n",
    "    'subsample':np.linspace(0.4,1,num=5),\n",
    "    'max_depth':[10,15,20,25],\n",
    "    'n_estimators':[100,200,300,400,500],\n",
    "    'reg_lambda':np.linspace(1,2,num=5),\n",
    "    'gamma':np.linspace(0,0.5,num=5)\n",
    "}\n",
    "\n",
    "# scoring = {\n",
    "#     'Accuracy':make_scorer(accuracy_score)\n",
    "# }\n",
    "\n",
    "num_folds = 10\n",
    "kfold = StratifiedKFold(n_splits=num_folds,random_state=123,shuffle=True)\n",
    "n_iter = 50\n",
    "grid=RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions = param_grid,\n",
    "    random_state=123,\n",
    "    cv = kfold,\n",
    "    n_jobs=-1,\n",
    "    n_iter=n_iter,\n",
    "    verbose=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training w/o sample weights\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_xgb = best_estimator.predict(X_test)\n",
    "pred_xgb_train = best_estimator.predict(X_train)\n",
    "print('Accuracy on test: {:.2f}'.format(accuracy_score(y_test,pred_xgb)))\n",
    "print('Accuracy on train: {:.2f}'.format(accuracy_score(y_train,pred_xgb_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator.fit(X,y,sample_weight=w_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_xgb = best_estimator.predict(test_matrix)\n",
    "test_data['importance']= pred_test_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[['appno','importance']].to_csv(os.path.join(result_path,'XGB_RandCV_cclbt02_md_25_est500_lr01_nl50_rlamb125_rand123_weights_Fin_Submission.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
